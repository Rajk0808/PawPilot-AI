{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14430446,"sourceType":"datasetVersion","datasetId":9217013}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the latest versions of necessary libraries\n!pip install -U transformers accelerate bitsandbytes qwen-vl-utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T11:58:08.968836Z","iopub.execute_input":"2026-01-16T11:58:08.969397Z","iopub.status.idle":"2026-01-16T11:58:27.923478Z","shell.execute_reply.started":"2026-01-16T11:58:08.969371Z","shell.execute_reply":"2026-01-16T11:58:27.922602Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nCollecting transformers\n  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nCollecting qwen-vl-utils\n  Downloading qwen_vl_utils-0.0.14-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\nCollecting av (from qwen-vl-utils)\n  Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils) (11.3.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\nDownloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading qwen_vl_utils-0.0.14-py3-none-any.whl (8.1 kB)\nDownloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (41.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: av, qwen-vl-utils, transformers, bitsandbytes, accelerate\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.57.1\n    Uninstalling transformers-4.57.1:\n      Successfully uninstalled transformers-4.57.1\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.11.0\n    Uninstalling accelerate-1.11.0:\n      Successfully uninstalled accelerate-1.11.0\nSuccessfully installed accelerate-1.12.0 av-16.1.0 bitsandbytes-0.49.1 qwen-vl-utils-0.0.14 transformers-4.57.6\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import warnings\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n    # code that triggers noisy deprecation warnings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T11:58:27.925085Z","iopub.execute_input":"2026-01-16T11:58:27.925343Z","iopub.status.idle":"2026-01-16T11:58:27.929709Z","shell.execute_reply.started":"2026-01-16T11:58:27.925316Z","shell.execute_reply":"2026-01-16T11:58:27.928972Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\n\n# Load the model with 4-bit quantization to save memory\nmodel_name = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n\nmodel = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\",\n    # trust_remote_code=True, # Uncomment if using older Qwen-VL versions\n)\n\n# Load the processor\nprocessor = AutoProcessor.from_pretrained(model_name)\n\nprint(f\"Model {model_name} loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T11:58:27.930562Z","iopub.execute_input":"2026-01-16T11:58:27.930917Z","iopub.status.idle":"2026-01-16T12:00:25.897060Z","shell.execute_reply.started":"2026-01-16T11:58:27.930897Z","shell.execute_reply":"2026-01-16T12:00:25.896368Z"}},"outputs":[{"name":"stderr","text":"2026-01-16 11:58:40.115538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768564720.295833      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768564720.349204      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768564720.793514      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768564720.793555      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768564720.793558      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768564720.793561      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eee3f7f5d56940d4928bfa02b855e807"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b277fcd15ec451eacce3bdc1ac37eb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c94dc9699af48bdb55a1cb7b7541635"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a51eee681f49508a2287adcda048f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da5392f581cc48f9a84162466ea7bfe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90dbe3ac5bc04063bf367dd7490f843d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/216 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dce45ba305a04113876c8c2257d01331"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56b9df1b03834f22b3ea97dea6d06f97"}},"metadata":{}},{"name":"stderr","text":"The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20e129cc78084a6db205ed62ca7d688d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad2a8779c79845139abe3dd6269f39ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff5dbc2c472148e5b1d660d73d66887c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43cbed1fcd09444f9328c989e0260e3b"}},"metadata":{}},{"name":"stderr","text":"'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 93dd84cc-0477-41db-a4d1-b88627d82457)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct/resolve/main/processor_config.json\nWARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 93dd84cc-0477-41db-a4d1-b88627d82457)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct/resolve/main/processor_config.json\nRetrying in 1s [Retry 1/5].\nWARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"chat_template.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"525199231477433aaab785e06356f676"}},"metadata":{}},{"name":"stdout","text":"Model Qwen/Qwen2.5-VL-3B-Instruct loaded successfully!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"image = \"/kaggle/input/toys-dataset/toys dataset/Ball_Launcher/image_012.jpg\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T12:00:25.897952Z","iopub.execute_input":"2026-01-16T12:00:25.900170Z","iopub.status.idle":"2026-01-16T12:00:25.904422Z","shell.execute_reply.started":"2026-01-16T12:00:25.900136Z","shell.execute_reply":"2026-01-16T12:00:25.903811Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 1. Prepare the input: An image and a question\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": image},\n            {\"type\": \"text\", \"text\": \"Describe this image in detail. and also detect the toy and describe it\"},\n        ],\n    }\n]\n\n# 2. Preprocess the inputs\ntext = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True )\nimage_inputs, video_inputs = process_vision_info(messages)\ninputs = processor(\n    text=[text],\n    images=image_inputs,\n    videos=video_inputs,\n    padding=True,\n    return_tensors=\"pt\",\n)\ninputs = inputs.to(\"cuda\")\n\n# 3. Generate the response\ngenerated_ids = model.generate(**inputs, max_new_tokens=512)\ngenerated_ids_trimmed = [\n    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n]\noutput_text = processor.batch_decode(\n    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n)\n\nprint(\"-\" * 30)\nprint(\"Model Response:\")\nprint(output_text[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T12:00:25.906170Z","iopub.execute_input":"2026-01-16T12:00:25.906518Z","iopub.status.idle":"2026-01-16T12:00:43.415472Z","shell.execute_reply.started":"2026-01-16T12:00:25.906485Z","shell.execute_reply":"2026-01-16T12:00:43.414817Z"}},"outputs":[{"name":"stdout","text":"------------------------------\nModel Response:\nThe image depicts a young girl playing with her dog in an outdoor setting, likely a park or a backyard. The girl is wearing a light blue shirt and light blue shorts, and she has a headband on. She is holding a green frisbee in her right hand, which is extended towards the dog.\n\nThe dog, a small breed with a white coat and brown patches, is standing on its hind legs, reaching up to catch the frisbee. The dog's front paws are off the ground, and it appears to be focused on the frisbee. The background shows a grassy area with some trees and bushes, indicating that the location is likely a natural, open space.\n\nThe toy in the image is a green frisbee. It is round and has a slightly glossy surface, reflecting some light. The frisbee is being held by the girl, and the dog is attempting to catch it. The frisbee's position suggests that it is in mid-air, just above the dog's reach.\n","output_type":"stream"}],"execution_count":5}]}